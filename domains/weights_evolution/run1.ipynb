{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 01:20:12.662409 11164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0913 01:20:12.674412 11164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0913 01:20:12.675412 11164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0913 01:20:12.696417 11164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0913 01:20:12.698417 11164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0913 01:20:12.703418 11164 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0913 01:20:12.755422 11164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0913 01:20:12.760423 11164 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0913 01:20:12.828438 11164 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 1.1308 - acc: 0.6494 - val_loss: 0.4495 - val_acc: 0.8563\n",
      "Test loss: 0.4494672349214554\n",
      "Test accuracy: 0.8563\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 2000\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data[2].astype(dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (3, 3, 1, 32), 2. (32,)\n",
      "3. (3, 3, 32, 64), 4. (64,)\n",
      "5. (9216, 128), 6. (128,)\n",
      "7. (128, 10), 8. (10,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(0,7,2):\n",
    "    print(str(i+1) + '. ' + str(model.get_weights()[i].shape) + ', ' + str(i+2) + '. '+str(model.get_weights()[i+1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_normal_noise(weights_shape, scaling='normalized'):\n",
    "    noise = np.random.normal(size=weights_shape)\n",
    "    if scaling == 'normalized':\n",
    "        noise =2*noise/(np.max(noise))\n",
    "    else:\n",
    "        noise = noise/2\n",
    "    return noise\n",
    "\n",
    "def generate_noisy_model(keras_model):\n",
    "    len_layers = len(keras_model.layers)\n",
    "    \n",
    "    for i in range(len_layers):\n",
    "        len_list_weights = len(keras_model.layers[i].get_weights())\n",
    "        weight_list_dummy = []\n",
    "        \n",
    "        for j in range(len_list_weights):\n",
    "            if keras_model.layers[i].get_weights()[j].size > 0:\n",
    "                weights_shape = keras_model.layers[i].get_weights()[j].shape\n",
    "                noise = gen_normal_noise(weights_shape)\n",
    "                \n",
    "                weight_list_dummy.append( keras_model.layers[i].get_weights()[j] + noise)\n",
    "        keras_model.layers[i].set_weights(weight_list_dummy)\n",
    "        del weight_list_dummy\n",
    "        return keras_model\n",
    "    \n",
    "def generate_population(keras_model, no_of_individuals):\n",
    "\n",
    "    accuracies = []\n",
    "    models = []\n",
    "    \n",
    "    for population in range(no_of_individuals):\n",
    "        new_model = generate_noisy_model(keras_model)\n",
    "        acc_dummy = new_model.evaluate(x_train, y_train, verbose=0)[1]\n",
    "        models.append(new_model)\n",
    "        accuracies.append(acc_dummy)\n",
    "        print('generating '+ str (population) + ' individual; acc: ' + str(acc_dummy))        \n",
    "        \n",
    "    return models, accuracies\n",
    "\n",
    "#findx incedes of max values in list\n",
    "def n_max_values(no_list, n):\n",
    "    idx =[]\n",
    "    dummy_no_list = no_list.copy()\n",
    "    for i in range(n):\n",
    "        idx.append(np.argmax( np.asarray(dummy_no_list) ))\n",
    "        no_list.pop(idx[i])\n",
    "        \n",
    "    return idx\n",
    "\n",
    "#for one dimensional number list\n",
    "def softmax(no_list):\n",
    "    L = -np.asarray(no_list)\n",
    "    denominator = np.sum( np.exp(L))\n",
    "    numerator = np.exp(L)\n",
    "    return numerator/denominator\n",
    "\n",
    "def select_fit_individuals(models, accuracies, no_to_select):\n",
    "    idx = n_max_values(accuracies, no_to_select)\n",
    "    selected_models = [models[i] for i in idx]\n",
    "    selected_acc = [accuracies[i] for i in idx]\n",
    "\n",
    "#     del models, accuracies\n",
    "    acc_prob = softmax(selected_acc)\n",
    "    return selected_models, acc_prob, selected_acc\n",
    "                         \n",
    "def generate_next_generation(selected_models, acc_prob, generation_population):\n",
    "    models_new_populations = []\n",
    "    \n",
    "    for i in range(len(acc_prob)):\n",
    "        models_new_populations.append(int(np.round(acc_prob[i]*generation_population)))\n",
    "        \n",
    "    new_models = []  \n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(len(models_new_populations)):\n",
    "        models, accuracy_s = generate_population(selected_models[i], models_new_populations[i])\n",
    "        print(accuracy_s)\n",
    "        new_models.extend(models)\n",
    "        accuracies.extend(accuracy_s)\n",
    "        \n",
    "    return new_models, accuracies\n",
    "                         \n",
    "def is_accurate_enough(accuracies, thresh):\n",
    "    idx = np.argmax( np.asarray(accuracies) )\n",
    "    accurate_enough = accuracies[idx] >= thresh\n",
    "    return accurate_enough, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating 0 individual; acc: 0.5031833333333333\n",
      "generating 1 individual; acc: 0.5613833333333333\n",
      "generating 2 individual; acc: 0.5564833333333333\n",
      "generating 0 individual; acc: 0.4523\n",
      "generating 1 individual; acc: 0.3713666666666667\n",
      "generating 2 individual; acc: 0.3268666666666667\n",
      "[0.4523, 0.3713666666666667, 0.3268666666666667]\n",
      "generating 0 individual; acc: 0.4345333333333333\n",
      "generating 1 individual; acc: 0.44931666666666664\n",
      "generating 2 individual; acc: 0.44216666666666665\n",
      "[0.4345333333333333, 0.44931666666666664, 0.44216666666666665]\n",
      "generating 0 individual; acc: 0.4614\n",
      "generating 1 individual; acc: 0.49966666666666665\n",
      "generating 2 individual; acc: 0.44055\n",
      "[0.4614, 0.49966666666666665, 0.44055]\n",
      "generating 0 individual; acc: 0.49966666666666665\n",
      "generating 1 individual; acc: 0.44693333333333335\n",
      "generating 2 individual; acc: 0.41441666666666666\n",
      "[0.49966666666666665, 0.44693333333333335, 0.41441666666666666]\n",
      "generating 0 individual; acc: 0.4366833333333333\n",
      "generating 1 individual; acc: 0.41276666666666667\n",
      "generating 2 individual; acc: 0.4070166666666667\n",
      "[0.4366833333333333, 0.41276666666666667, 0.4070166666666667]\n",
      "generating 0 individual; acc: 0.37505\n",
      "generating 1 individual; acc: 0.41376666666666667\n",
      "generating 2 individual; acc: 0.41376666666666667\n",
      "[0.37505, 0.41376666666666667, 0.41376666666666667]\n",
      "generating 0 individual; acc: 0.41428333333333334\n",
      "generating 1 individual; acc: 0.3809666666666667\n",
      "generating 2 individual; acc: 0.39698333333333335\n",
      "[0.41428333333333334, 0.3809666666666667, 0.39698333333333335]\n",
      "generating 0 individual; acc: 0.4035\n",
      "generating 1 individual; acc: 0.40263333333333334\n",
      "generating 2 individual; acc: 0.3544833333333333\n",
      "[0.4035, 0.40263333333333334, 0.3544833333333333]\n",
      "generating 0 individual; acc: 0.32106666666666667\n",
      "generating 1 individual; acc: 0.3162\n",
      "generating 2 individual; acc: 0.30501666666666666\n",
      "[0.32106666666666667, 0.3162, 0.30501666666666666]\n",
      "generating 0 individual; acc: 0.3063\n",
      "generating 1 individual; acc: 0.34136666666666665\n",
      "generating 2 individual; acc: 0.30583333333333335\n",
      "[0.3063, 0.34136666666666665, 0.30583333333333335]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "gen_population = 3\n",
    "no_to_select = 1\n",
    "\n",
    "models, accuracies = generate_population(model, gen_population)\n",
    "for i in range(epochs):\n",
    "    selected_models, acc_prob, selected_acc = select_fit_individuals(models, accuracies, no_to_select)\n",
    "    del accuracies\n",
    "    models, accuracies = generate_next_generation(selected_models, acc_prob, gen_population)\n",
    "    accurate_enough, idx = is_accurate_enough(accuracies, .6)\n",
    "    if accurate_enough:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-f10d43ad3092>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_max_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mselected_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2c28d2c332cd>\u001b[0m in \u001b[0;36mn_max_values\u001b[1;34m(no_list, n)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mdummy_no_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mno_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0midx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy_no_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mno_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \"\"\"\n\u001b[1;32m-> 1103\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].get_weights()[0][3] == model.layers[1].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].get_weights()[1] == model.layers[1].get_weights()[0][0][0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
