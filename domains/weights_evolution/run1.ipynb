{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 13:38:44.002986  2600 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0913 13:38:44.023991  2600 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0913 13:38:44.028992  2600 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0913 13:38:44.055998  2600 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0913 13:38:44.057998  2600 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0913 13:38:44.063000  2600 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0913 13:38:44.118012  2600 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0913 13:38:44.124014  2600 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 13:38:44.198030  2600 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 1.1960 - acc: 0.6278 - val_loss: 0.3695 - val_acc: 0.8990\n",
      "Test loss: 0.3695025020122528\n",
      "Test accuracy: 0.899\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 2000\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data[2].astype(dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (3, 3, 1, 32), 2. (32,)\n",
      "3. (3, 3, 32, 64), 4. (64,)\n",
      "5. (9216, 128), 6. (128,)\n",
      "7. (128, 10), 8. (10,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(0,7,2):\n",
    "    print(str(i+1) + '. ' + str(model.get_weights()[i].shape) + ', ' + str(i+2) + '. '+str(model.get_weights()[i+1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_normal_noise(weights_shape, scaling='normalized'):\n",
    "    noise = np.random.normal(size=weights_shape)\n",
    "    if scaling == 'normalized':\n",
    "        noise =2*noise/(np.max(noise))\n",
    "    else:\n",
    "        noise = noise/2\n",
    "    return noise\n",
    "\n",
    "def generate_noisy_model(keras_model):\n",
    "    len_layers = len(keras_model.layers)\n",
    "    \n",
    "    for i in range(len_layers):\n",
    "        len_list_weights = len(keras_model.layers[i].get_weights())\n",
    "        weight_list_dummy = []\n",
    "        \n",
    "        for j in range(len_list_weights):\n",
    "            if keras_model.layers[i].get_weights()[j].size > 0:\n",
    "                weights_shape = keras_model.layers[i].get_weights()[j].shape\n",
    "                noise = gen_normal_noise(weights_shape)\n",
    "                \n",
    "                weight_list_dummy.append( keras_model.layers[i].get_weights()[j] + noise)\n",
    "        keras_model.layers[i].set_weights(weight_list_dummy)\n",
    "        del weight_list_dummy\n",
    "        return keras_model\n",
    "    \n",
    "def generate_population(keras_model, no_of_individuals):\n",
    "\n",
    "    accuracies = []\n",
    "    models = []\n",
    "    \n",
    "    for population in range(no_of_individuals):\n",
    "        new_model = generate_noisy_model(keras_model)\n",
    "        acc_dummy = new_model.evaluate(x_train, y_train, verbose=0)[1]\n",
    "        models.append(new_model)\n",
    "        accuracies.append(acc_dummy)\n",
    "        print('generating '+ str (population) + ' individual; acc: ' + str(acc_dummy))        \n",
    "        \n",
    "    return models, accuracies\n",
    "\n",
    "#findx incedes of max values in list\n",
    "def n_max_values(no_list, n):\n",
    "    idx =[]\n",
    "    dummy_no_list = no_list.copy()\n",
    "    for i in range(n):\n",
    "        idx.append(np.argmax( np.asarray(dummy_no_list) ))\n",
    "        dummy_no_list.pop(idx[i])\n",
    "        \n",
    "    return idx\n",
    "\n",
    "#for one dimensional number list\n",
    "def softmax(no_list):\n",
    "    L = -np.asarray(no_list)\n",
    "    denominator = np.sum( np.exp(L))\n",
    "    numerator = np.exp(L)\n",
    "    return numerator/denominator\n",
    "\n",
    "def select_fit_individuals(models, accuracies, no_to_select):\n",
    "    idx = n_max_values(accuracies, no_to_select)\n",
    "    selected_models = [models[i] for i in idx]\n",
    "    selected_acc = [accuracies[i] for i in idx]\n",
    "\n",
    "#     del models, accuracies\n",
    "    acc_prob = softmax(selected_acc)\n",
    "    return selected_models, acc_prob, selected_acc\n",
    "                         \n",
    "def generate_next_generation(selected_models, acc_prob, generation_population):\n",
    "    models_new_populations = []\n",
    "    \n",
    "    for i in range(len(acc_prob)):\n",
    "        models_new_populations.append(int(np.round(acc_prob[i]*generation_population)))\n",
    "        \n",
    "    new_models = []  \n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(len(models_new_populations)):\n",
    "        models, accuracy_s = generate_population(selected_models[i], models_new_populations[i])\n",
    "        print(accuracy_s)\n",
    "        new_models.extend(models)\n",
    "        accuracies.extend(accuracy_s)\n",
    "        \n",
    "    return new_models, accuracies\n",
    "                         \n",
    "def is_accurate_enough(accuracies, thresh):\n",
    "    idx = np.argmax( np.asarray(accuracies) )\n",
    "    accurate_enough = accuracies[idx] >= thresh\n",
    "    return accurate_enough, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating 0 individual; acc: 0.5417833333333333\n",
      "generating 1 individual; acc: 0.5272833333333333\n",
      "generating 2 individual; acc: 0.60065\n",
      "generating 3 individual; acc: 0.49948333333333333\n",
      "generating 4 individual; acc: 0.5567333333333333\n",
      "generating 5 individual; acc: 0.6384333333333333\n",
      "generating 6 individual; acc: 0.6384833333333333\n",
      "generating 7 individual; acc: 0.5135333333333333\n",
      "generating 8 individual; acc: 0.5004166666666666\n",
      "generating 9 individual; acc: 0.49998333333333334\n",
      "generating 0 individual; acc: 0.49885\n",
      "generating 1 individual; acc: 0.49865\n",
      "generating 2 individual; acc: 0.4391833333333333\n",
      "[0.49885, 0.49865, 0.4391833333333333]\n",
      "generating 0 individual; acc: 0.4701666666666667\n",
      "generating 1 individual; acc: 0.4180833333333333\n",
      "generating 2 individual; acc: 0.40165\n",
      "[0.4701666666666667, 0.4180833333333333, 0.40165]\n",
      "generating 0 individual; acc: 0.38171666666666665\n",
      "generating 1 individual; acc: 0.3562666666666667\n",
      "generating 2 individual; acc: 0.3745\n",
      "[0.38171666666666665, 0.3562666666666667, 0.3745]\n",
      "generating 0 individual; acc: 0.42138333333333333\n",
      "generating 1 individual; acc: 0.35101666666666664\n",
      "generating 2 individual; acc: 0.3066\n",
      "[0.42138333333333333, 0.35101666666666664, 0.3066]\n",
      "generating 0 individual; acc: 0.27448333333333336\n",
      "generating 1 individual; acc: 0.2932166666666667\n",
      "generating 2 individual; acc: 0.29556666666666664\n",
      "[0.27448333333333336, 0.2932166666666667, 0.29556666666666664]\n",
      "generating 0 individual; acc: 0.2517333333333333\n",
      "generating 1 individual; acc: 0.23443333333333333\n",
      "generating 2 individual; acc: 0.20836666666666667\n",
      "[0.2517333333333333, 0.23443333333333333, 0.20836666666666667]\n",
      "generating 0 individual; acc: 0.2162\n",
      "generating 1 individual; acc: 0.22128333333333333\n",
      "generating 2 individual; acc: 0.23533333333333334\n",
      "[0.2162, 0.22128333333333333, 0.23533333333333334]\n",
      "generating 0 individual; acc: 0.25765\n",
      "generating 1 individual; acc: 0.2665166666666667\n",
      "generating 2 individual; acc: 0.25255\n",
      "[0.25765, 0.2665166666666667, 0.25255]\n",
      "generating 0 individual; acc: 0.25925\n",
      "generating 1 individual; acc: 0.24133333333333334\n",
      "generating 2 individual; acc: 0.27265\n",
      "[0.25925, 0.24133333333333334, 0.27265]\n",
      "generating 0 individual; acc: 0.25753333333333334\n",
      "generating 1 individual; acc: 0.29413333333333336\n",
      "generating 2 individual; acc: 0.25655\n",
      "[0.25753333333333334, 0.29413333333333336, 0.25655]\n",
      "generating 0 individual; acc: 0.3113666666666667\n",
      "generating 1 individual; acc: 0.34753333333333336\n",
      "generating 2 individual; acc: 0.36906666666666665\n",
      "[0.3113666666666667, 0.34753333333333336, 0.36906666666666665]\n",
      "generating 0 individual; acc: 0.38298333333333334\n",
      "generating 1 individual; acc: 0.39036666666666664\n",
      "generating 2 individual; acc: 0.3973833333333333\n",
      "[0.38298333333333334, 0.39036666666666664, 0.3973833333333333]\n",
      "generating 0 individual; acc: 0.39476666666666665\n",
      "generating 1 individual; acc: 0.3743\n",
      "generating 2 individual; acc: 0.34578333333333333\n",
      "[0.39476666666666665, 0.3743, 0.34578333333333333]\n",
      "generating 0 individual; acc: 0.33886666666666665\n",
      "generating 1 individual; acc: 0.31453333333333333\n",
      "generating 2 individual; acc: 0.30775\n",
      "[0.33886666666666665, 0.31453333333333333, 0.30775]\n",
      "generating 0 individual; acc: 0.29396666666666665\n",
      "generating 1 individual; acc: 0.2387\n",
      "generating 2 individual; acc: 0.2337\n",
      "[0.29396666666666665, 0.2387, 0.2337]\n",
      "generating 0 individual; acc: 0.20961666666666667\n",
      "generating 1 individual; acc: 0.2146\n",
      "generating 2 individual; acc: 0.20753333333333332\n",
      "[0.20961666666666667, 0.2146, 0.20753333333333332]\n",
      "generating 0 individual; acc: 0.19165\n",
      "generating 1 individual; acc: 0.20375\n",
      "generating 2 individual; acc: 0.2055\n",
      "[0.19165, 0.20375, 0.2055]\n",
      "generating 0 individual; acc: 0.19443333333333335\n",
      "generating 1 individual; acc: 0.1908\n",
      "generating 2 individual; acc: 0.1856\n",
      "[0.19443333333333335, 0.1908, 0.1856]\n",
      "generating 0 individual; acc: 0.1768\n",
      "generating 1 individual; acc: 0.17641666666666667\n",
      "generating 2 individual; acc: 0.17111666666666667\n",
      "[0.1768, 0.17641666666666667, 0.17111666666666667]\n",
      "generating 0 individual; acc: 0.172\n",
      "generating 1 individual; acc: 0.1723\n",
      "generating 2 individual; acc: 0.17158333333333334\n",
      "[0.172, 0.1723, 0.17158333333333334]\n",
      "generating 0 individual; acc: 0.1888\n",
      "generating 1 individual; acc: 0.18566666666666667\n",
      "generating 2 individual; acc: 0.18921666666666667\n",
      "[0.1888, 0.18566666666666667, 0.18921666666666667]\n",
      "generating 0 individual; acc: 0.19101666666666667\n",
      "generating 1 individual; acc: 0.19661666666666666\n",
      "generating 2 individual; acc: 0.18826666666666667\n",
      "[0.19101666666666667, 0.19661666666666666, 0.18826666666666667]\n",
      "generating 0 individual; acc: 0.2029\n",
      "generating 1 individual; acc: 0.21373333333333333\n",
      "generating 2 individual; acc: 0.2206\n",
      "[0.2029, 0.21373333333333333, 0.2206]\n",
      "generating 0 individual; acc: 0.22706666666666667\n",
      "generating 1 individual; acc: 0.21338333333333334\n",
      "generating 2 individual; acc: 0.20015\n",
      "[0.22706666666666667, 0.21338333333333334, 0.20015]\n",
      "generating 0 individual; acc: 0.19543333333333332\n",
      "generating 1 individual; acc: 0.18775\n",
      "generating 2 individual; acc: 0.19356666666666666\n",
      "[0.19543333333333332, 0.18775, 0.19356666666666666]\n",
      "generating 0 individual; acc: 0.19411666666666666\n",
      "generating 1 individual; acc: 0.18978333333333333\n",
      "generating 2 individual; acc: 0.19986666666666666\n",
      "[0.19411666666666666, 0.18978333333333333, 0.19986666666666666]\n",
      "generating 0 individual; acc: 0.20091666666666666\n",
      "generating 1 individual; acc: 0.20381666666666667\n",
      "generating 2 individual; acc: 0.20226666666666668\n",
      "[0.20091666666666666, 0.20381666666666667, 0.20226666666666668]\n",
      "generating 0 individual; acc: 0.19265\n",
      "generating 1 individual; acc: 0.19408333333333333\n",
      "generating 2 individual; acc: 0.20553333333333335\n",
      "[0.19265, 0.19408333333333333, 0.20553333333333335]\n",
      "generating 0 individual; acc: 0.19825\n",
      "generating 1 individual; acc: 0.19528333333333334\n",
      "generating 2 individual; acc: 0.195\n",
      "[0.19825, 0.19528333333333334, 0.195]\n",
      "generating 0 individual; acc: 0.194\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-92cbb1a02b21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mselected_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_fit_individuals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_to_select\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_next_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_population\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0maccurate_enough\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_accurate_enough\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccurate_enough\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-f4d9ea467fa4>\u001b[0m in \u001b[0;36mgenerate_next_generation\u001b[1;34m(selected_models, acc_prob, generation_population)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_new_populations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_population\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels_new_populations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mnew_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-f4d9ea467fa4>\u001b[0m in \u001b[0;36mgenerate_population\u001b[1;34m(keras_model, no_of_individuals)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_of_individuals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mnew_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_noisy_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0macc_dummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0maccuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_dummy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1111\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m                                          steps=steps)\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m     def predict(self, x,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "gen_population = 10\n",
    "no_to_select = 3\n",
    "\n",
    "models, accuracies = generate_population(model, gen_population)\n",
    "for i in range(epochs):\n",
    "    selected_models, acc_prob, selected_acc = select_fit_individuals(models, accuracies, no_to_select)\n",
    "    del accuracies\n",
    "    models, accuracies = generate_next_generation(selected_models, acc_prob, gen_population)\n",
    "    accurate_enough, idx = is_accurate_enough(accuracies, .6)\n",
    "    if accurate_enough:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].get_weights()[0][3] == model.layers[1].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].get_weights()[1] == model.layers[1].get_weights()[0][0][0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
